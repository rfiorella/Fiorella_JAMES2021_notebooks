{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720c3614",
   "metadata": {},
   "source": [
    "# Script 01: Process CESM output for figures\n",
    "Rich Fiorella, 3/11/2021.\n",
    "\n",
    "This script reads in iCAM5, iCAM6 (nudged and free) data and pre-processes it to create standardized output files that can be used to run the scripts downstream.\n",
    "\n",
    "The remaining scripts (02 - isotope figures/comparison of CAM5 and CAM6; 03 - figures relating to testing rainout hypotheses; 04 - figures relating to residence time; 05 - figures related to d-excess variability testing; 06 - correlation time dependence (daily, monthly vs interannual))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d78c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up packages and data\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "from cftime import DatetimeNoLeap\n",
    "import h5py\n",
    "\n",
    "\n",
    "# calculate d18O_0, need to filter for things above x mm/day\n",
    "thres = 0.1 # mm/day \n",
    "thres_mps = thres*(1/86400)*(1/1000) # convert mm/day -> m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be673a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/1142966018.py:46: SerializationWarning: saving variable TMQ with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds_free.to_netcdf('../proc_data/iCAM6_free_monthly.nc')\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/1142966018.py:46: SerializationWarning: saving variable LANDFRAC with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds_free.to_netcdf('../proc_data/iCAM6_free_monthly.nc')\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/1142966018.py:46: SerializationWarning: saving variable TS with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds_free.to_netcdf('../proc_data/iCAM6_free_monthly.nc')\n"
     ]
    }
   ],
   "source": [
    "# Process iCAM6 - free for seasonal averages\n",
    "\n",
    "ds_free = xr.open_dataset(\"..//raw_data/ts_free_subset_2x2.nc\", decode_timedelta = False).drop('time_bnds')\n",
    "ds_free\n",
    "#===============================\n",
    "#-------------------------------\n",
    "# work through free dataset.\n",
    "\n",
    "# filter out values below thres_mps?\n",
    "ds_free['PRECT'] = ds_free['PRECT'].where(ds_free.PRECT > thres_mps, thres_mps)\n",
    "\n",
    "# PRECTtime between 0 and 60\n",
    "ds_free['PRECTtime'] = ds_free['PRECTtime'].where(ds_free.PRECTtime < 40, 40)\n",
    "ds_free['PRECTtime'] = ds_free['PRECTtime'].where(ds_free.PRECTtime > 0, 0)\n",
    "\n",
    "# d180 between -70 and +10\n",
    "ds_free['PRECT_d18O'] = ds_free['PRECT_d18O'].where(ds_free.PRECT_d18O > -70, -70)\n",
    "ds_free['PRECT_d18O'] = ds_free['PRECT_d18O'].where(ds_free.PRECT_d18O < 10, 10)\n",
    "\n",
    "# d-excess between -50 and 50\n",
    "ds_free['PRECT_dxs'] = ds_free['PRECT_dxs'].where(ds_free.PRECT_dxs > -25, -25)\n",
    "ds_free['PRECT_dxs'] = ds_free['PRECT_dxs'].where(ds_free.PRECT_dxs < 50, 50)\n",
    "\n",
    "# take seasonally weighted averages\n",
    "#---------------------------------\n",
    "# shift to get correct months! (UGHHHHH)\n",
    "# for some reason, xarray reads in the end of the averaging time rather\n",
    "# than the midpoint of the averaged month (UGH)\n",
    "# fix from here: https://bb.cgd.ucar.edu/cesm/threads/external-tools-dont-like-cesm-time-coordinate.4604/\n",
    "time_index_shifted = ds_free.time.get_index('time') - timedelta(days=1) \n",
    "ds_free['time'] = time_index_shifted\n",
    "\n",
    "# calculate weighted mean using code from xarray tutorial:\n",
    "# http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "month_length = ds_free.time.dt.days_in_month\n",
    "# Calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# Test that the sum of the weights for each season is 1.0\n",
    "np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "# Calculate the weighted average\n",
    "ds_free_weighted = (ds_free * weights).groupby('time.season').sum(dim='time')\n",
    "\n",
    "# write out files.\n",
    "ds_free.to_netcdf('../proc_data/iCAM6_free_monthly.nc')\n",
    "ds_free_weighted.sel(season='JJA').to_netcdf('../proc_data/iCAM6_free_JJA.nc')\n",
    "ds_free_weighted.sel(season='DJF').to_netcdf('../proc_data/iCAM6_free_DJF.nc')\n",
    "ds_free.mean(dim=\"time\").to_netcdf('../proc_data/iCAM6_free_ANN.nc')\n",
    "\n",
    "ds_free\n",
    "\n",
    "del ds_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb37ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process iCAM6 - nudged for seasonal averages\n",
    "\n",
    "ds_nudg = xr.open_dataset(\"../raw_data/ts_nudg_subset_2x2.nc\", decode_timedelta = False).drop('time_bnds')\n",
    "\n",
    "# filter out values below thres_mps?\n",
    "ds_nudg['PRECT'] = ds_nudg['PRECT'].where(ds_nudg.PRECT > thres_mps, thres_mps)\n",
    "\n",
    "# PRECTtime between 0 and 60\n",
    "ds_nudg['PRECTtime'] = ds_nudg['PRECTtime'].where(ds_nudg.PRECTtime < 40, 40)\n",
    "ds_nudg['PRECTtime'] = ds_nudg['PRECTtime'].where(ds_nudg.PRECTtime > 0, 0)\n",
    "\n",
    "# d180 between -70 and +10\n",
    "ds_nudg['PRECT_d18O'] = ds_nudg['PRECT_d18O'].where(ds_nudg.PRECT_d18O > -70, -70)\n",
    "ds_nudg['PRECT_d18O'] = ds_nudg['PRECT_d18O'].where(ds_nudg.PRECT_d18O < 10, 10)\n",
    "\n",
    "# d-excess between -50 and 50\n",
    "ds_nudg['PRECT_dxs'] = ds_nudg['PRECT_dxs'].where(ds_nudg.PRECT_dxs > -25, -25)\n",
    "ds_nudg['PRECT_dxs'] = ds_nudg['PRECT_dxs'].where(ds_nudg.PRECT_dxs < 50, 50)\n",
    "\n",
    "# take seasonally weighted averages\n",
    "#---------------------------------\n",
    "# shift to get correct months! (UGHHHHH)\n",
    "# for some reason, xarray reads in the end of the averaging time rather\n",
    "# than the midpoint of the averaged month (UGH)\n",
    "# fix from here: https://bb.cgd.ucar.edu/cesm/threads/external-tools-dont-like-cesm-time-coordinate.4604/\n",
    "time_index_shifted = ds_nudg.time.get_index('time') - timedelta(days=1) \n",
    "ds_nudg['time'] = time_index_shifted\n",
    "\n",
    "# calculate weighted mean using code from xarray tutorial:\n",
    "# http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "month_length = ds_nudg.time.dt.days_in_month\n",
    "# Calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# Test that the sum of the weights for each season is 1.0\n",
    "np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "# Calculate the weighted average\n",
    "ds_nudg_weighted = (ds_nudg * weights).groupby('time.season').sum(dim='time')\n",
    "\n",
    "# write out files.\n",
    "ds_nudg_weighted.sel(season='JJA').to_netcdf('../proc_data/iCAM6_nudg_JJA.nc')\n",
    "ds_nudg_weighted.sel(season='DJF').to_netcdf('../proc_data/iCAM6_nudg_DJF.nc')\n",
    "ds_nudg.mean(dim=\"time\").to_netcdf('../proc_data/iCAM6_nudg_ANN.nc')\n",
    "\n",
    "del ds_nudg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd4cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/core/computation.py:769: RuntimeWarning: overflow encountered in exp\n",
      "  result_data = func(*input_data)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/core/computation.py:769: RuntimeWarning: divide by zero encountered in log\n",
      "  result_data = func(*input_data)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/489157480.py:102: SerializationWarning: saving variable TMQ with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf('../proc_data/iCAM6_nudg_monthly.nc')\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:173: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"_FillValue\"] = dtype.type(fv)\n",
      "/Users/rfiorella/opt/anaconda3/envs/xarray/lib/python3.9/site-packages/xarray/coding/variables.py:180: RuntimeWarning: invalid value encountered in cast\n",
      "  encoding[\"missing_value\"] = dtype.type(mv)\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/489157480.py:102: SerializationWarning: saving variable LANDFRAC with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf('../proc_data/iCAM6_nudg_monthly.nc')\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/489157480.py:102: SerializationWarning: saving variable TS with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf('../proc_data/iCAM6_nudg_monthly.nc')\n",
      "/var/folders/vz/51v7vlnd3xd6dctwmyrstss00000gn/T/ipykernel_5136/489157480.py:102: SerializationWarning: saving variable PRECT2 with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf('../proc_data/iCAM6_nudg_monthly.nc')\n"
     ]
    }
   ],
   "source": [
    "# various steps to process nudged file for files 03, 04, and 05.\n",
    "ds = xr.open_dataset(\"../raw_data/ts_nudg_subset_2x2.nc\", decode_timedelta = False).drop('time_bnds')\n",
    "\n",
    "#-------------------------------\n",
    "# Apply some important thresholds.\n",
    "# some values get numerically unstable at low PRECT rates,\n",
    "# so need to threshold values.\n",
    "\n",
    "# calculate d18O_0, need to filter for things above x mm/day\n",
    "thres = 0.1 # mm/day \n",
    "thres_mps = thres*(1/86400)*(1/1000) # convert mm/day -> m/s\n",
    "\n",
    "ds['PRECT2'] = ds['PRECT'] # keep a copy of PRECT before thresholding for anomaly stuff?\n",
    "\n",
    "# filter out values below thres_mps?\n",
    "ds['PRECT'] = ds['PRECT'].where(ds.PRECT > thres_mps, thres_mps)\n",
    "\n",
    "# d180 between -70 and +10\n",
    "ds['PRECT_d18O'] = ds['PRECT_d18O'].where(ds.PRECT_d18O > -70, -70)\n",
    "ds['PRECT_d18O'] = ds['PRECT_d18O'].where(ds.PRECT_d18O < 10, 10)\n",
    "\n",
    "# constant frac d180 between -70 and +10\n",
    "ds['PRECT_d18Oec'] = ds['PRECT_d18Oec'].where(ds.PRECT_d18Oec > -70, -70)\n",
    "ds['PRECT_d18Oec'] = ds['PRECT_d18Oec'].where(ds.PRECT_d18Oec < 10, 10)\n",
    "\n",
    "# d-excess between -50 and 50\n",
    "ds['PRECT_dxs'] = ds['PRECT_dxs'].where(ds.PRECT_dxs > -25, -25)\n",
    "ds['PRECT_dxs'] = ds['PRECT_dxs'].where(ds.PRECT_dxs < 50, 50)\n",
    "\n",
    "# d180 between -500 and +50\n",
    "#ds['PRECT_d2H'] = ds['PRECT_d2H'].where(ds.PRECT_d2H > -500, -500)\n",
    "#ds['PRECT_d2H'] = ds['PRECT_d2H'].where(ds.PRECT_d2H < 50, 50)\n",
    "\n",
    "# d-excess between -50 and 50\n",
    "ds['PRECT_dxs'] = ds['PRECT_dxs'].where(ds.PRECT_dxs > -25, -25)\n",
    "ds['PRECT_dxs'] = ds['PRECT_dxs'].where(ds.PRECT_dxs < 50, 50)\n",
    "\n",
    "# evap d180 between -70 and +10\n",
    "ds['PRECTed18O'] = ds['PRECTed18O'].where(ds.PRECTed18O > -70, -70)\n",
    "ds['PRECTed18O'] = ds['PRECTed18O'].where(ds.PRECTed18O < 40, 40)\n",
    "\n",
    "# evap d180 between -70 and +10\n",
    "ds['PRECTed18O'] = ds['PRECTed18O'].where(ds.PRECTed18O > -70, -70)\n",
    "ds['PRECTed18O'] = ds['PRECTed18O'].where(ds.PRECTed18O < 40, 40)\n",
    "\n",
    "# PRECTct between 200 and 325K\n",
    "ds['PRECTct'] = ds['PRECTct'].where(ds.PRECTct > 200, 200)\n",
    "ds['PRECTct'] = ds['PRECTct'].where(ds.PRECTct < 325, 325)\n",
    "\n",
    "# PRECTct between 200 and 325K\n",
    "ds['PRECTtsrf'] = ds['PRECTtsrf'].where(ds.PRECTct > 200, 200)\n",
    "ds['PRECTtsrf'] = ds['PRECTtsrf'].where(ds.PRECTct < 350, 350)\n",
    "\n",
    "# PRECTrh between 0 and 100\n",
    "ds['PRECTrhsrf'] = ds['PRECTrhsrf'].where(ds.PRECTrhsrf > 0, 0)\n",
    "ds['PRECTrhsrf'] = ds['PRECTrhsrf'].where(ds.PRECTrhsrf < 100, 100)\n",
    "\n",
    "# PRECTlnf between -6 and 0\n",
    "ds['PRECTlnf'] = ds['PRECTlnf'].where(ds.PRECTlnf < 0, 0)\n",
    "ds['PRECTlnf'] = ds['PRECTlnf'].where(ds.PRECTlnf > -6, -6)\n",
    "\n",
    "# PRECTews between 0 and 25\n",
    "ds['PRECTews'] = ds['PRECTews'].where(ds.PRECTews < 25, 25)\n",
    "ds['PRECTews'] = ds['PRECTews'].where(ds.PRECTews > 0, 0)\n",
    "\n",
    "# PRECTtime between 0 and 60\n",
    "ds['PRECTtime'] = ds['PRECTtime'].where(ds.PRECTtime < 40, 40)\n",
    "ds['PRECTtime'] = ds['PRECTtime'].where(ds.PRECTtime > 0, 0)\n",
    "\n",
    "# PRECTdist between 0 and 100000\n",
    "ds['PRECTdist'] = ds['PRECTdist'].where(ds.PRECTdist < 100000, 100000)\n",
    "ds['PRECTdist'] = ds['PRECTdist'].where(ds.PRECTdist > 0, 0)\n",
    "\n",
    "#-------------------------------------\n",
    "# Calculate some new variables at monthly resolution:\n",
    "#-------------------------------------\n",
    "# add d'18O as well:\n",
    "ds['log_d18O'] = np.log(ds.PRECT_d18O/1000 + 1) # set threshold.\n",
    "\n",
    "# calculate liquid water in eq. w/ ed18O.\n",
    "ds['tlaE'] = 0.35e9/(ds.PRECTtsrf-((100-ds.PRECTrhsrf)/5))**3\\\n",
    "            -1.666e6/(ds.PRECTtsrf-((100-ds.PRECTrhsrf)/5))**2\\\n",
    "            +6.712e3/(ds.PRECTtsrf-((100-ds.PRECTrhsrf)/5))-7.685\n",
    "ds['alphaE'] = np.exp(ds.tlaE/1000)\n",
    "ds['d18O_0'] = 1000*(ds.alphaE*(ds.PRECTed18O/1000+1)-1)\n",
    "\n",
    "# monthly discrimination below evap-corrected d0\n",
    "ds['D18O'] = (ds.PRECT_d18O-ds.d18O_0)/(1+ds.d18O_0/1000)\n",
    "ds['log_D18O'] = np.log(ds.D18O/1000 + 1)\n",
    "\n",
    "ds['qonp'] = (ds.TMQ/1000)/ds.PRECT/86400 # convert to days from seconds\n",
    "\n",
    "ds['PRECTedxs'] = ds.PRECTed2H - 8*ds.PRECTed18O\n",
    "\n",
    "ds['dxs_diff'] = (ds.PRECT_dxs - ds.PRECTedxs)\n",
    "\n",
    "ds['d18O_anom_norm'] = (ds.PRECT_d18O - ds.PRECT_d18O.mean(dim=\"time\"))/ds.PRECT_d18O.mean(dim=\"time\")\n",
    "ds['RT_anom_norm']   = (ds.PRECTtime - ds.PRECTtime.mean(dim=\"time\"))/ds.PRECTtime.mean(dim=\"time\")\n",
    "ds['qonp_anom_norm'] = (ds.qonp - ds.qonp.mean(dim=\"time\"))/ds.qonp.mean(dim=\"time\")\n",
    "\n",
    "# write monthly timeseries.\n",
    "ds.to_netcdf('../proc_data/iCAM6_nudg_monthly.nc')\n",
    "\n",
    "#------------------------------------\n",
    "# get long-term monthly averages.\n",
    "tmp = ds * ds['PRECT']\n",
    "monthly_avr = tmp.groupby('time.month').sum(dim='time')/\\\n",
    "                ds['PRECT'].groupby('time.month').sum('time')\n",
    "\n",
    "monthly_avr.assign_coords({'lat': ds.lat,\n",
    "              'lon': ds.lon})\n",
    "\n",
    "monthly_avr.to_netcdf(\"../proc_data/iCAM6_nudg_MonAvg.nc\")\n",
    "\n",
    "# take seasonally weighted averages\n",
    "#---------------------------------\n",
    "# shift to get correct months! (UGHHHHH)\n",
    "# for some reason, xarray reads in the end of the averaging time rather\n",
    "# than the midpoint of the averaged month (UGH)\n",
    "# fix from here: https://bb.cgd.ucar.edu/cesm/threads/external-tools-dont-like-cesm-time-coordinate.4604/\n",
    "time_index_shifted = ds.time.get_index('time') - timedelta(days=1) \n",
    "ds['time'] = time_index_shifted\n",
    "\n",
    "# calculate weighted mean using code from xarray tutorial:\n",
    "# http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "month_length = ds.time.dt.days_in_month\n",
    "# Calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# Test that the sum of the weights for each season is 1.0\n",
    "np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "# Calculate the weighted average\n",
    "ds_weighted = (ds * weights).groupby('time.season').sum(dim='time')\n",
    "ds_unweighted = ds.groupby('time.season').mean(dim='time')\n",
    "\n",
    "ds_weighted.to_netcdf(\"../proc_data/iCAM6_nudg_WgtSeasAvg.nc\")\n",
    "ds_unweighted.to_netcdf(\"../proc_data/iCAM6_nudg_UnwgtSeasAvg.nc\")\n",
    "#-------------------\n",
    "# Calculate annual averages:\n",
    "# calculate some precip-weighted time means\n",
    "# uncorrected evaporation d18O\n",
    "tmp = ds.PRECT * ds.PRECTed18O.where(ds.PRECTed18O > -100, -100)\n",
    "ed18O_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted precipitation d18O\n",
    "tmp = ds.PRECT * ds.PRECT_d18O.where(ds.PRECT_d18O > -100, -100)\n",
    "d18O_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted precipitation d-excess\n",
    "tmp = ds.PRECT * ds.PRECT_dxs\n",
    "dxs_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted evap temperature\n",
    "tmp = ds.PRECT * ds.PRECTtsrf\n",
    "tsrf_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted evap relative humidity\n",
    "tmp = ds.PRECT * ds.PRECTrhsrf\n",
    "rh_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted constant fractionation d18O\n",
    "tmp = ds.PRECT * ds.PRECT_d18Oec.where(ds.PRECT_d18Oec > -100, -100)\n",
    "d18Ocf_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted ln(q/q0) = ln(f)\n",
    "tmp = ds.PRECT * ds.PRECTlnf\n",
    "lnf_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted condensation temperature\n",
    "tmp = ds.PRECT * ds.PRECTct\n",
    "tcond_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted D18O\n",
    "tmp = ds.PRECT * ds.D18O.where(ds.D18O > -100, -100)\n",
    "D18O_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted residence time\n",
    "tmp = ds.PRECT * ds.PRECTtime\n",
    "time_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted transport distance\n",
    "tmp = ds.PRECT * ds.PRECTdist\n",
    "dist_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted evaporation wind speed\n",
    "tmp = ds.PRECT * ds.PRECTews\n",
    "ews_wgt = tmp.sum(dim=\"time\") / ds.PRECT.sum(dim=\"time\")\n",
    "\n",
    "# mass-weighted d-excess diference\n",
    "tmp = ds.PRECT * ds.dxs_diff\n",
    "dxsdiff_wgt = tmp.sum(dim='time')/ds.PRECT.sum(dim='time')\n",
    "\n",
    "tmq_wgt = ds.TMQ.mean(dim=\"time\")/1000 # convert from kg/m2 to m\n",
    "\n",
    "qonp_wgt = ds.qonp.mean(dim=\"time\")\n",
    "\n",
    "#------------------------------\n",
    "# add some derived versions - log of d18O+1, evap-corrected d18O, log(d18O+1)cfe\n",
    "d18O_log   = np.log(d18O_wgt.where(d18O_wgt > -100, -100)/1000 + 1)\n",
    "d18Ocf_log = np.log(d18Ocf_wgt.where(d18Ocf_wgt > -100, -100)/1000 + 1)\n",
    "D18O_log   = np.log(D18O_wgt.where(D18O_wgt > -100, -100)/1000 + 1)\n",
    "tmq_log    = np.log10(tmq_wgt)\n",
    "qonp_log   = np.log10(qonp_wgt)\n",
    "time_log   = np.log10(time_wgt)\n",
    "\n",
    "# finally, convert these to a new xarray dataset that we can use for plotting.\n",
    "ds_p1 = xr.Dataset(\n",
    "    data_vars={'mean_d18O':(('lat','lon'), d18O_wgt.data),\n",
    "               'log_d18O':(('lat','lon'), d18O_log.data),\n",
    "               'mean_d18Ocf':(('lat','lon'), d18Ocf_wgt.data),\n",
    "               'log_d18Ocf':(('lat','lon'), d18Ocf_log.data),\n",
    "               'mean_lnf': (('lat','lon'), lnf_wgt.data),\n",
    "               'mean_Tc':  (('lat','lon'), tcond_wgt.data),\n",
    "               'mean_Te':  (('lat','lon'), tsrf_wgt.data),\n",
    "               'mean_RH':  (('lat','lon'), rh_wgt.data),\n",
    "               'evap_d18O':(('lat','lon'), ed18O_wgt.data),\n",
    "               'mean_D18O':(('lat','lon'), D18O_wgt.data),\n",
    "               'log_D18O' :(('lat','lon'), D18O_log.data),\n",
    "               'landfrac' :(('lat','lon'), ds.isel(time=1).LANDFRAC.data),\n",
    "               'PRECT'    :(('lat','lon'), ds.PRECT.mean(dim='time').data),\n",
    "               'mean_RT':  (('lat','lon'), time_wgt.data),\n",
    "               'mean_dist':  (('lat','lon'), dist_wgt.data),\n",
    "               'log_RT':   (('lat','lon'), time_log.data),\n",
    "               'mean_TMQ': (('lat','lon'), tmq_wgt.data),\n",
    "               'log_TMQ':  (('lat','lon'), tmq_log.data),\n",
    "               'mean_qonp': (('lat','lon'), qonp_wgt.data),\n",
    "               'log_qonp': (('lat','lon'), qonp_log.data),\n",
    "               'mean_dxs': (('lat','lon'), dxs_wgt.data),\n",
    "               'mean_ews': (('lat','lon'), ews_wgt.data),\n",
    "               'mean_dxsdiff': (('lat','lon'),dxsdiff_wgt.data)\n",
    "               },\n",
    "    coords = {'lat': ds.lat.data,\n",
    "              'lon': ds.lon.data}\n",
    "    )\n",
    "\n",
    "ds_p1.to_netcdf('../proc_data/iCAM6_nudg_AnnAvg.nc')\n",
    "\n",
    "del ds_p1\n",
    "del ds\n",
    "del monthly_avr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a4fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process iCAM6 - nudged for seasonal averages\n",
    "\n",
    "ds_icam5 = xr.open_dataset(\"../raw_data/icam5_19802004.nc\", decode_timedelta = False).drop('time_bnds')\n",
    "\n",
    "# take seasonally weighted averages\n",
    "#---------------------------------\n",
    "# shift to get correct months! (UGHHHHH)\n",
    "# for some reason, xarray reads in the end of the averaging time rather\n",
    "# than the midpoint of the averaged month (UGH)\n",
    "# fix from here: https://bb.cgd.ucar.edu/cesm/threads/external-tools-dont-like-cesm-time-coordinate.4604/\n",
    "time_index_shifted = ds_icam5.time.get_index('time') - timedelta(days=1) \n",
    "ds_icam5['time'] = time_index_shifted\n",
    "\n",
    "# calculate weighted mean using code from xarray tutorial:\n",
    "# http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "month_length = ds_icam5.time.dt.days_in_month\n",
    "# Calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# Test that the sum of the weights for each season is 1.0\n",
    "np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "# Calculate the weighted average\n",
    "ds_icam5_weighted = (ds_icam5 * weights).groupby('time.season').sum(dim='time')\n",
    "\n",
    "# d180 between -70 and +10\n",
    "ds_icam5_weighted['PRECT_d18O'] = 1000*(ds_icam5_weighted.PRECT_H218O/ds_icam5_weighted.PRECT_H216O-1)\n",
    "ds_icam5_weighted['PRECT_d18O'] = ds_icam5_weighted['PRECT_d18O'].where(ds_icam5_weighted.PRECT_d18O > -70, -70)\n",
    "ds_icam5_weighted['PRECT_d18O'] = ds_icam5_weighted['PRECT_d18O'].where(ds_icam5_weighted.PRECT_d18O < 10, 10)\n",
    "\n",
    "# d2H between -600 and +50\n",
    "ds_icam5_weighted['PRECT_d2H'] = 1000*(ds_icam5_weighted.PRECT_HDO/ds_icam5_weighted.PRECT_H216O-1)\n",
    "ds_icam5_weighted['PRECT_d2H'] = ds_icam5_weighted['PRECT_d2H'].where(ds_icam5_weighted.PRECT_d2H > -600, -600)\n",
    "ds_icam5_weighted['PRECT_d2H'] = ds_icam5_weighted['PRECT_d2H'].where(ds_icam5_weighted.PRECT_d2H < 80, 80)\n",
    "\n",
    "# d180 between -70 and +10\n",
    "ds_icam5_weighted['PRECT_dxs'] = ds_icam5_weighted.PRECT_d2H - 8*ds_icam5_weighted.PRECT_d18O\n",
    "ds_icam5_weighted['PRECT_dxs'] = ds_icam5_weighted['PRECT_dxs'].where(ds_icam5_weighted.PRECT_dxs > -50, -50)\n",
    "ds_icam5_weighted['PRECT_dxs'] = ds_icam5_weighted['PRECT_dxs'].where(ds_icam5_weighted.PRECT_dxs < 50, 50)\n",
    "\n",
    "ds_icam5_weighted\n",
    "\n",
    "# write out files.\n",
    "ds_icam5_weighted.sel(season='JJA').to_netcdf('../proc_data/iCAM5_free_JJA.nc')\n",
    "ds_icam5_weighted.sel(season='DJF').to_netcdf('../proc_data/iCAM5_free_DJF.nc')\n",
    "ds_icam5_weighted.mean(dim=\"season\").to_netcdf('../proc_data/iCAM5_free_ANN.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
